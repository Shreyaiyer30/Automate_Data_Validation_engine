# ğŸ§¹ Automated Data Validation & Cleaning Engine (DataClean Pro)

A fully automated, rule-driven **data quality, validation, and cleaning platform** built with Python, Pandas, NumPy, and Streamlit.  
Designed with **enterprise-grade data integrity guarantees**, deterministic pipelines, and audit-level traceability.

---

## ğŸš€ Key Features

- ğŸ“Š **Data Quality Profiling & Overview**
- ğŸ§  **Rule-Based Cleaning Lab**
- âœ… **Post-Clean Validation Engine**
- ğŸ“ˆ **Raw vs Cleaned Data Visualization**
- ğŸ“¥ **Deterministic CSV / Excel Export**
- ğŸ§¾ **Full Audit & Lineage Tracking**
- ğŸ¯ **Objective Data Quality Scoring (0â€“100)**

---

## ğŸ—ï¸ Logical Architecture Overview

The system enforces a **strict linear pipeline**.  
Each stage acts as a gatekeeper for the next.

UPLOAD
â†“
RAW OVERVIEW
â†“
PROFILING & ANALYSIS
â†“
CLEANING LAB
â†“
VALIDATION
â†“
VISUALIZATION
â†“
EXPORT & REPORTING


### Pipeline Failure Semantics

Each stage emits a terminal state:

| State | Meaning |
|------|--------|
| PASS | Stage completed successfully |
| WARN | Non-fatal issues detected (penalties applied) |
| FAIL | Critical integrity breach â€” pipeline stops |

---

## ğŸ§¬ Data State Model (Immutable by Design)

| State | Description | Mutability |
|-----|------------|-----------|
| Raw Dataset | Original uploaded data | READ-ONLY |
| Analyzed Dataset | Raw data + statistical metadata | READ-ONLY |
| Cleaned Dataset | Output of deterministic cleaning rules | IMMUTABLE |

---

## ğŸ” Data Profiling & Analysis

The profiling engine generates a **Statistical Signature** without modifying data.

### Guarantees
- Intelligent **data type inference** (majority-based)
- Precise **missing value detection**
  - `null`, `NaN`, empty strings, whitespace
- **Cardinality analysis** (ID vs categorical)
- **Outlier likelihood detection** via distribution skew

---

## ğŸ§ª Cleaning Lab (Logic-Only, Deterministic)

Cleaning transforms Raw â†’ Cleaned data **only through explicit rules**.

### Supported Cleaning Operations

- Missing value imputation (type-aware)
- Date & time normalization
- Outlier clipping (IQR / Z-score)
- Text sanitization & standardization
- Data type enforcement
- Range & constraint enforcement
- Cross-column consistency checks
- Scaling & normalization
- Duplicate row & column removal

### Rule Precedence Hierarchy

1. Domain constraints (hard rules)
2. Data type enforcement
3. Statistical heuristics
4. Cosmetic standardization

Every transformation is logged in the **Audit Trail**.

---

## ğŸ·ï¸ Column Header Normalization (Critical Contract)

Column headers in the **Cleaned Dataset** are normalized for clarity and consistency.

### Normalization Rules
- Trim whitespace
- Replace `_` and `.` with spaces
- Resolve duplicate columns
- Convert to **Title Case**

Example:
title_year â†’ Title Year
title_year.1 â†’ Title Year (2)


### Dataset Scope

| Dataset | Header Behavior |
|------|----------------|
| Raw | Original headers preserved |
| Analyzed | Mirrors raw headers |
| Cleaned | Normalized (Title Case) |

---

## âœ… Validation Engine

Validation is **read-only** and runs *after cleaning*.

### Validation Checks
- Missing value validation
- Duplicate detection
- Range & constraint validation
- Outlier validation
- Categorical validation
- Date & time validation
- Cross-column validation
- Statistical drift detection

âŒ Validation never modifies data  
âœ… Only flags issues & adjusts Quality Score

---

## ğŸ“Š Data Quality Score (0â€“100)

An objective measurement of dataset fitness.

### Scoring Logic
- Start at **100**
- Missing value penalties (weighted)
- Duplicate density penalties (exponential)
- Constraint violations (fixed deductions)
- Outlier volume penalties
- Semantic drift penalties

Column importance can be **user-defined or auto-inferred**.

---

## ğŸ“ˆ Visualization Layer

- Raw vs Cleaned comparisons
- Missing value heatmaps
- Distribution & outlier plots
- Drift indicators

ğŸ“Œ All visuals use the **same statistics** as the scoring engine  
ğŸ“Œ No recomputation or divergence allowed

---

## ğŸ“¤ Export & Download Behavior

### Cleaned File Naming Contract (MANDATORY)

<original_filename>_cleaned_data.<extension>


#### Examples

| Original | Cleaned |
|--------|--------|
| abc.csv | abc_cleaned_data.csv |
| movies.xlsx | movies_cleaned_data.xlsx |

### Export Guarantees
- No overwriting original files
- One-to-one raw â†’ cleaned mapping
- CSV â†’ CSV, Excel â†’ Excel
- Export blocked if cleaning FAILS

### Excel Enhancements
- Fixed / frozen header row
- Table formatting
- Auto-width columns

---

## ğŸ§¾ Audit & Traceability

Every operation is recorded:

- Rule ID
- Affected rows
- Value deltas
- Original vs cleaned filename
- Header normalization mapping
- Cleaning configuration version

This ensures **full lineage and reproducibility**.

---

## ğŸ–¥ï¸ UI Consistency Rules

- Navigation is **state-locked**
- Visualization unavailable until Cleaned Dataset exists
- Changing rules recalculates **Projected Quality Score**
- Cleaned headers displayed consistently across UI

---

## ğŸ› ï¸ Tech Stack

- **Python**
- **Pandas**
- **NumPy**
- **Streamlit**
- **OpenPyXL / CSV**

---

## ğŸ¯ Why This Project Matters

This system demonstrates:
- Real-world data engineering discipline
- Deterministic pipelines
- Audit-safe data transformations
- Enterprise-grade UX + data integrity
- Production-ready validation logic

---

## ğŸ“Œ Status

âœ… Core pipeline implemented  
ğŸ”§ Actively enhancing UI, validation depth, and scalability

---

## ğŸ“œ License

MIT License
